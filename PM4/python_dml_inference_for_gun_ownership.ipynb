{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wbh466Asi-5n",
        "papermill": {
          "duration": 0.024906,
          "end_time": "2021-07-23T16:17:55.704014",
          "exception": false,
          "start_time": "2021-07-23T16:17:55.679108",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# A Case Study: The Effect of Gun Ownership on Gun-Homicide Rates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WACAA85ci-5z",
        "papermill": {
          "duration": 0.024533,
          "end_time": "2021-07-23T16:17:55.753444",
          "exception": false,
          "start_time": "2021-07-23T16:17:55.728911",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "\n",
        "We consider the problem of estimating the effect of gun ownership on the homicide rate. For this purpose, we perform inference on $\\beta$ in the following the partially linear model:\n",
        "$$\n",
        "Y_{j, t}=\\beta D_{j,(t-1)}+g\\left(X_{j, t}, \\bar{X}_j, \\bar{X}_t, X_{j, 0}, Y_{j, 0}, t\\right)+\\epsilon_{j, t}\n",
        "$$\n",
        "$Y_{j, t}$ is the log homicide rate in county $j$ at time $t. D_{j, t-1}$ is the log fraction of suicides committed with a firearm in county $j$ at time $t-1$, which we use as a proxy for gun ownership $G_{j, t}$, which is not observed. $X_{j, t}$ is a set of demographic and economic characteristics of county $j$ at time $t$. We use $\\bar{X}_j$ to denote the within county average of $X_{j, t}$ and $\\bar{X}_t$ to denote the within time period average of $X_{j, t} . X_{j, 0}$ and $Y_{j, 0}$ denote initial conditions in county $j$. We use $Z_{j, t}$ to denote the set of observed control variables $\\left\\{X_{j, t}, \\bar{X}_j, \\bar{X}_t, X_{j, 0}, Y_{j, 0}, t\\right\\}$, so that our model is\n",
        "\n",
        "$$\n",
        " Y_{i,t} = \\beta D_{i,(t-1)} + g(Z_{i,t}) + \\epsilon_{i,t}.\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOcTlYfPi-5z",
        "papermill": {
          "duration": 0.024711,
          "end_time": "2021-07-23T16:17:55.803109",
          "exception": false,
          "start_time": "2021-07-23T16:17:55.778398",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btLKXBrUi-5z",
        "papermill": {
          "duration": 0.025115,
          "end_time": "2021-07-23T16:17:55.854426",
          "exception": false,
          "start_time": "2021-07-23T16:17:55.829311",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "$Y_{j,t}$ is the log homicide rate in county $j$ at time $t$, $D_{j, t-1}$ is the log fraction of suicides committed with a firearm in county $j$ at time $t-1$, which we use as a proxy for gun ownership,  and  $Z_{j,t}$ is a set of demographic and economic characteristics of county $j$ at time $t$. Assuming the firearm suicide rate is a good proxy for gun ownership, the parameter $\\beta$ is the effect of gun ownership on homicide rates, controlling for county-level demographic and economic characteristics.\n",
        "\n",
        "The sample covers 195 large United States counties between the years 1980 through 1999, giving us 3900 observations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "x4283h0kwo_M"
      },
      "outputs": [],
      "source": [
        "# Import relevant packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.model_selection import cross_val_predict, KFold\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.linear_model import LassoCV, RidgeCV, ElasticNetCV, LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "import warnings\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "np.random.seed(1234)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "g6JCZCdqvj1Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf6bb9f2-3def-4125-a213-3fa64c45375b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1937, 73)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "file = \"/content/sample_data/main.dta\"\n",
        "data = pd.read_stata(file)\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufg-P0ujU6f_",
        "outputId": "979adcb4-98a9-43cc-c9ad-946f57d6e9aa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1937 entries, 0 to 1936\n",
            "Data columns (total 73 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   province           1937 non-null   object \n",
            " 1   lati               1937 non-null   float32\n",
            " 2   near_dist          1937 non-null   float32\n",
            " 3   pat_per15          1937 non-null   float32\n",
            " 4   gdpp               1937 non-null   float32\n",
            " 5   samplenorth        1937 non-null   float32\n",
            " 6   ele                1937 non-null   float32\n",
            " 7   maizev             1937 non-null   float32\n",
            " 8   ricewheat          1937 non-null   float32\n",
            " 9   interricevm        1937 non-null   float32\n",
            " 10  interwheatvm       1937 non-null   float32\n",
            " 11  d                  1937 non-null   int8   \n",
            " 12  edu                1937 non-null   float32\n",
            " 13  above65            1937 non-null   float64\n",
            " 14  migrenkou          1937 non-null   float32\n",
            " 15  lower15            1937 non-null   float64\n",
            " 16  r_pca1             1569 non-null   float32\n",
            " 17  pat_per_0115       1937 non-null   float32\n",
            " 18  pat_per_0610       1937 non-null   float32\n",
            " 19  pat_per_1115       1937 non-null   float32\n",
            " 20  qu                 1937 non-null   float32\n",
            " 21  shi                1937 non-null   float32\n",
            " 22  rice_area1         1937 non-null   float32\n",
            " 23  wheat_area1        1937 non-null   float32\n",
            " 24  rice_production1   1937 non-null   float32\n",
            " 25  wheat_production1  1937 non-null   float32\n",
            " 26  corru              1937 non-null   float32\n",
            " 27  i_1900             1937 non-null   float32\n",
            " 28  riceh              1567 non-null   float64\n",
            " 29  wheath             1567 non-null   float64\n",
            " 30  t                  1937 non-null   float32\n",
            " 31  p                  1937 non-null   float32\n",
            " 32  border             856 non-null    float32\n",
            " 33  song               188 non-null    float32\n",
            " 34  ming               126 non-null    float32\n",
            " 35  coast              768 non-null    float32\n",
            " 36  special            377 non-null    float32\n",
            " 37  stk2006_per_1      1937 non-null   float32\n",
            " 38  _est_m1            1937 non-null   int8   \n",
            " 39  _est_m2            1937 non-null   int8   \n",
            " 40  _est_m3            1937 non-null   int8   \n",
            " 41  _est_m4            1937 non-null   int8   \n",
            " 42  _est_m5            1937 non-null   int8   \n",
            " 43  _est_m6            1937 non-null   int8   \n",
            " 44  _est_m7            1937 non-null   int8   \n",
            " 45  _est_m8            1937 non-null   int8   \n",
            " 46  _Iprovince_2       1937 non-null   int8   \n",
            " 47  _Iprovince_3       1937 non-null   int8   \n",
            " 48  _Iprovince_4       1937 non-null   int8   \n",
            " 49  _Iprovince_5       1937 non-null   int8   \n",
            " 50  _Iprovince_6       1937 non-null   int8   \n",
            " 51  _Iprovince_7       1937 non-null   int8   \n",
            " 52  _Iprovince_8       1937 non-null   int8   \n",
            " 53  _Iprovince_9       1937 non-null   int8   \n",
            " 54  _Iprovince_10      1937 non-null   int8   \n",
            " 55  _Iprovince_11      1937 non-null   int8   \n",
            " 56  _Iprovince_12      1937 non-null   int8   \n",
            " 57  _Iprovince_13      1937 non-null   int8   \n",
            " 58  _Iprovince_14      1937 non-null   int8   \n",
            " 59  _Iprovince_15      1937 non-null   int8   \n",
            " 60  _Iprovince_16      1937 non-null   int8   \n",
            " 61  _Iprovince_17      1937 non-null   int8   \n",
            " 62  _Iprovince_18      1937 non-null   int8   \n",
            " 63  _Iprovince_19      1937 non-null   int8   \n",
            " 64  _Iprovince_20      1937 non-null   int8   \n",
            " 65  _Iprovince_21      1937 non-null   int8   \n",
            " 66  _Iprovince_22      1937 non-null   int8   \n",
            " 67  _Iprovince_23      1937 non-null   int8   \n",
            " 68  _Iprovince_24      1937 non-null   int8   \n",
            " 69  _Iprovince_25      1937 non-null   int8   \n",
            " 70  _Iprovince_26      1937 non-null   int8   \n",
            " 71  _Iprovince_27      1937 non-null   int8   \n",
            " 72  _est_m9            1937 non-null   int8   \n",
            "dtypes: float32(32), float64(4), int8(36), object(1)\n",
            "memory usage: 386.0+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['interricevm'].describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "qjoJvDudawSl",
        "outputId": "892c6168-103e-43ac-975d-d7fc5994ebe8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    1937.000000\n",
              "mean        0.041127\n",
              "std         0.053162\n",
              "min         0.000000\n",
              "25%         0.000567\n",
              "50%         0.020750\n",
              "75%         0.059994\n",
              "max         0.204782\n",
              "Name: interricevm, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>interricevm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1937.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.041127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.053162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.020750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.059994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.204782</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the threshold for rice suitability (e.g., median)\n",
        "df = data.copy()\n",
        "threshold_rice = df['interricevm'].median()\n",
        "\n",
        "# Create the dummy variable: 1 for high suitability, 0 for low suitability\n",
        "df['interricevm_dummy'] = (df['interricevm'] > threshold_rice).astype(int)\n",
        "\n",
        "# Check the new dummy variable\n",
        "print(df[['interricevm', 'interricevm_dummy']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_f5WCUocatJ",
        "outputId": "ebc4ca24-a600-47c8-9606-0cd24fa4a693"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   interricevm  interricevm_dummy\n",
            "0     0.077000                  1\n",
            "1     0.153256                  1\n",
            "2     0.019850                  0\n",
            "3     0.164175                  1\n",
            "4     0.082059                  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "D = interwheatvm_dummy"
      ],
      "metadata": {
        "id": "kDoJVLUv9Bt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X1 = df[\"samplenorth\"] + df[\"near_dist\"] + df[\"ele\",\"lat\", \"i_1900\", \"d\", \"t\", \"p\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "id": "Ya4ZyWhAiSCY",
        "outputId": "7e686a62-bf28-4258-989d-065262c34ecd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "('ele', 'lat', 'i_1900', 'd', 't', 'p')",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: ('ele', 'lat', 'i_1900', 'd', 't', 'p')",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-c2d63a9878ba>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"samplenorth\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"near_dist\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ele\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"lat\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"i_1900\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"p\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: ('ele', 'lat', 'i_1900', 'd', 't', 'p')"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlVEEVRRlefo",
        "papermill": {
          "duration": 0.02615,
          "end_time": "2021-07-23T16:18:24.461261",
          "exception": false,
          "start_time": "2021-07-23T16:18:24.435111",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Estimation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vN70lvlTlefo",
        "papermill": {
          "duration": 0.02615,
          "end_time": "2021-07-23T16:18:24.513673",
          "exception": false,
          "start_time": "2021-07-23T16:18:24.487523",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Baseline OLS Estimates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ms333iuflefp",
        "papermill": {
          "duration": 0.027888,
          "end_time": "2021-07-23T16:18:24.568278",
          "exception": false,
          "start_time": "2021-07-23T16:18:24.540390",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "After preprocessing the data, as a baseline model, we first look at simple regression of $Y_{j,t}$ on $D_{j,t-1}$ without controls in the full data set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMqfimTCbW-y"
      },
      "source": [
        "\n",
        "\n",
        "Next we estimate with the baseline set of controls."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22N1iDA8lnUm",
        "papermill": {
          "duration": 0.043087,
          "end_time": "2021-07-23T16:18:25.122084",
          "exception": false,
          "start_time": "2021-07-23T16:18:25.078997",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "<!-- Since our goal is to estimate the effect of gun ownership after controlling for a rich set county characteristics, we next include time and space averages. -->\n",
        "\n",
        "We can also run our regression with time and space averages as controls."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfk4t3O-nQPA"
      },
      "source": [
        "Since our goal is to estimate the effect of gun ownership after controlling for a rich set county characteristics, we now include all controls."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "TQ0uPQvwlcZ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cecd5d1-756a-4779-b0fe-7e26f14dd687"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OLS Coefficients:\n",
            "const               -0.001907\n",
            "interricevm_dummy   -0.000703\n",
            "samplenorth         -0.001019\n",
            "near_dist           -0.000069\n",
            "ele                  0.000050\n",
            "lati                 0.000018\n",
            "i_1900               0.000037\n",
            "d                    0.000100\n",
            "t                    0.000211\n",
            "p                   -0.000311\n",
            "dtype: float64\n",
            "\n",
            "Standard Errors:\n",
            "-0.001907068885168552: const\n",
            "-0.0007028748430942484: interricevm_dummy\n",
            "-0.0010186592816147596: samplenorth\n",
            "-6.851197569991093e-05: near_dist\n",
            "5.021685361754247e-05: ele\n",
            "1.7671197569358403e-05: lati\n",
            "3.660665642407836e-05: i_1900\n",
            "0.0001003393155659479: d\n",
            "0.00021089677973827318: t\n",
            "-0.0003107348774941093: p\n"
          ]
        }
      ],
      "source": [
        "# Regression on all controls\n",
        "\n",
        "# Define the control variables (sum of certain variables + other selected variables)\n",
        "X1 = df[[\"samplenorth\", \"near_dist\", \"ele\", \"lati\", \"i_1900\", \"d\", \"t\", \"p\"]]  # Fixed the missing comma\n",
        "\n",
        "# Define the treatment variables (assuming these are already defined)\n",
        "# If you haven't already defined `T` as treatment variables, you can add them like this:\n",
        "T = df[['interricevm_dummy']]  # For example, assuming dummies are used for treatment variables\n",
        "\n",
        "# Combine treatment and control variables\n",
        "X = pd.concat([T, X1], axis=1)  # Concatenate treatment and control variables column-wise\n",
        "\n",
        "# Add a constant (intercept) term to the combined treatment and control variables\n",
        "X_with_constant = sm.add_constant(X)  # Adding the intercept term\n",
        "\n",
        "# Define the outcome variable (patent per capita)\n",
        "y = df['pat_per15']  # Assuming this is your dependent variable\n",
        "\n",
        "# Fit the OLS regression model\n",
        "lm0 = sm.OLS(y, X_with_constant).fit(cov_type='HC3')  # Fit the model with robust standard errors (HC3)\n",
        "\n",
        "# Print the coefficients and robust standard errors\n",
        "print(\"OLS Coefficients:\")\n",
        "print(lm0.params)\n",
        "\n",
        "# Extract the covariance matrix and calculate standard errors\n",
        "vc0 = lm0.cov_params()  # Covariance matrix of the model parameters\n",
        "\n",
        "# Print the coefficients and standard errors\n",
        "std_err = np.sqrt(vc0.loc[['interricevm_dummy']])\n",
        "print(\"\\nStandard Errors:\")\n",
        "for coef, se in zip(lm0.params, std_err):\n",
        "    print(f\"{coef}: {se}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lm0.summary()"
      ],
      "metadata": {
        "id": "afev4KSSkvzN",
        "outputId": "acf9404e-9992-4b8c-d178-5fa9d9b6da0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:              pat_per15   R-squared:                       0.142\n",
              "Model:                            OLS   Adj. R-squared:                  0.138\n",
              "Method:                 Least Squares   F-statistic:                     18.68\n",
              "Date:                Mon, 02 Dec 2024   Prob (F-statistic):           3.72e-30\n",
              "Time:                        06:02:52   Log-Likelihood:                 10112.\n",
              "No. Observations:                1937   AIC:                        -2.020e+04\n",
              "Df Residuals:                    1927   BIC:                        -2.015e+04\n",
              "Df Model:                           9                                         \n",
              "Covariance Type:                  HC3                                         \n",
              "=====================================================================================\n",
              "                        coef    std err          z      P>|z|      [0.025      0.975]\n",
              "-------------------------------------------------------------------------------------\n",
              "const                -0.0019      0.002     -1.095      0.274      -0.005       0.002\n",
              "interricevm_dummy    -0.0007      0.000     -4.755      0.000      -0.001      -0.000\n",
              "samplenorth          -0.0010      0.000     -7.520      0.000      -0.001      -0.001\n",
              "near_dist         -6.851e-05   1.04e-05     -6.592      0.000   -8.89e-05   -4.81e-05\n",
              "ele                5.022e-05      0.000      0.335      0.737      -0.000       0.000\n",
              "lati               1.767e-05   7.74e-06      2.283      0.022     2.5e-06    3.28e-05\n",
              "i_1900             3.661e-05    9.9e-06      3.699      0.000    1.72e-05     5.6e-05\n",
              "d                     0.0001   9.57e-05      1.049      0.294   -8.72e-05       0.000\n",
              "t                     0.0002      0.000      1.672      0.095   -3.63e-05       0.000\n",
              "p                    -0.0003      0.001     -0.572      0.568      -0.001       0.001\n",
              "==============================================================================\n",
              "Omnibus:                     2125.860   Durbin-Watson:                   1.888\n",
              "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           144709.028\n",
              "Skew:                           5.571   Prob(JB):                         0.00\n",
              "Kurtosis:                      43.851   Cond. No.                     3.06e+03\n",
              "==============================================================================\n",
              "\n",
              "Notes:\n",
              "[1] Standard Errors are heteroscedasticity robust (HC3)\n",
              "[2] The condition number is large, 3.06e+03. This might indicate that there are\n",
              "strong multicollinearity or other numerical problems.\n",
              "\"\"\""
            ],
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>        <td>pat_per15</td>    <th>  R-squared:         </th>  <td>   0.142</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.138</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   18.68</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Mon, 02 Dec 2024</td> <th>  Prob (F-statistic):</th>  <td>3.72e-30</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>06:02:52</td>     <th>  Log-Likelihood:    </th>  <td>  10112.</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>  1937</td>      <th>  AIC:               </th> <td>-2.020e+04</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>  1927</td>      <th>  BIC:               </th> <td>-2.015e+04</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     9</td>      <th>                     </th>      <td> </td>    \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>         <td>HC3</td>       <th>                     </th>      <td> </td>    \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "          <td></td>             <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th>             <td>   -0.0019</td> <td>    0.002</td> <td>   -1.095</td> <td> 0.274</td> <td>   -0.005</td> <td>    0.002</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>interricevm_dummy</th> <td>   -0.0007</td> <td>    0.000</td> <td>   -4.755</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.000</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>samplenorth</th>       <td>   -0.0010</td> <td>    0.000</td> <td>   -7.520</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.001</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>near_dist</th>         <td>-6.851e-05</td> <td> 1.04e-05</td> <td>   -6.592</td> <td> 0.000</td> <td>-8.89e-05</td> <td>-4.81e-05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>ele</th>               <td> 5.022e-05</td> <td>    0.000</td> <td>    0.335</td> <td> 0.737</td> <td>   -0.000</td> <td>    0.000</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>lati</th>              <td> 1.767e-05</td> <td> 7.74e-06</td> <td>    2.283</td> <td> 0.022</td> <td>  2.5e-06</td> <td> 3.28e-05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>i_1900</th>            <td> 3.661e-05</td> <td>  9.9e-06</td> <td>    3.699</td> <td> 0.000</td> <td> 1.72e-05</td> <td>  5.6e-05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>d</th>                 <td>    0.0001</td> <td> 9.57e-05</td> <td>    1.049</td> <td> 0.294</td> <td>-8.72e-05</td> <td>    0.000</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>t</th>                 <td>    0.0002</td> <td>    0.000</td> <td>    1.672</td> <td> 0.095</td> <td>-3.63e-05</td> <td>    0.000</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>p</th>                 <td>   -0.0003</td> <td>    0.001</td> <td>   -0.572</td> <td> 0.568</td> <td>   -0.001</td> <td>    0.001</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td>2125.860</td> <th>  Durbin-Watson:     </th>  <td>   1.888</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>144709.028</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>           <td> 5.571</td>  <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>       <td>43.851</td>  <th>  Cond. No.          </th>  <td>3.06e+03</td> \n",
              "</tr>\n",
              "</table><br/><br/>Notes:<br/>[1] Standard Errors are heteroscedasticity robust (HC3)<br/>[2] The condition number is large, 3.06e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
            ],
            "text/latex": "\\begin{center}\n\\begin{tabular}{lclc}\n\\toprule\n\\textbf{Dep. Variable:}     &    pat\\_per15    & \\textbf{  R-squared:         } &     0.142   \\\\\n\\textbf{Model:}             &       OLS        & \\textbf{  Adj. R-squared:    } &     0.138   \\\\\n\\textbf{Method:}            &  Least Squares   & \\textbf{  F-statistic:       } &     18.68   \\\\\n\\textbf{Date:}              & Mon, 02 Dec 2024 & \\textbf{  Prob (F-statistic):} &  3.72e-30   \\\\\n\\textbf{Time:}              &     06:02:52     & \\textbf{  Log-Likelihood:    } &    10112.   \\\\\n\\textbf{No. Observations:}  &        1937      & \\textbf{  AIC:               } & -2.020e+04  \\\\\n\\textbf{Df Residuals:}      &        1927      & \\textbf{  BIC:               } & -2.015e+04  \\\\\n\\textbf{Df Model:}          &           9      & \\textbf{                     } &             \\\\\n\\textbf{Covariance Type:}   &       HC3        & \\textbf{                     } &             \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lcccccc}\n                            & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n\\midrule\n\\textbf{const}              &      -0.0019  &        0.002     &    -1.095  &         0.274        &       -0.005    &        0.002     \\\\\n\\textbf{interricevm\\_dummy} &      -0.0007  &        0.000     &    -4.755  &         0.000        &       -0.001    &       -0.000     \\\\\n\\textbf{samplenorth}        &      -0.0010  &        0.000     &    -7.520  &         0.000        &       -0.001    &       -0.001     \\\\\n\\textbf{near\\_dist}         &   -6.851e-05  &     1.04e-05     &    -6.592  &         0.000        &    -8.89e-05    &    -4.81e-05     \\\\\n\\textbf{ele}                &    5.022e-05  &        0.000     &     0.335  &         0.737        &       -0.000    &        0.000     \\\\\n\\textbf{lati}               &    1.767e-05  &     7.74e-06     &     2.283  &         0.022        &      2.5e-06    &     3.28e-05     \\\\\n\\textbf{i\\_1900}            &    3.661e-05  &      9.9e-06     &     3.699  &         0.000        &     1.72e-05    &      5.6e-05     \\\\\n\\textbf{d}                  &       0.0001  &     9.57e-05     &     1.049  &         0.294        &    -8.72e-05    &        0.000     \\\\\n\\textbf{t}                  &       0.0002  &        0.000     &     1.672  &         0.095        &    -3.63e-05    &        0.000     \\\\\n\\textbf{p}                  &      -0.0003  &        0.001     &    -0.572  &         0.568        &       -0.001    &        0.001     \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lclc}\n\\textbf{Omnibus:}       & 2125.860 & \\textbf{  Durbin-Watson:     } &     1.888   \\\\\n\\textbf{Prob(Omnibus):} &   0.000  & \\textbf{  Jarque-Bera (JB):  } & 144709.028  \\\\\n\\textbf{Skew:}          &   5.571  & \\textbf{  Prob(JB):          } &      0.00   \\\\\n\\textbf{Kurtosis:}      &  43.851  & \\textbf{  Cond. No.          } &  3.06e+03   \\\\\n\\bottomrule\n\\end{tabular}\n%\\caption{OLS Regression Results}\n\\end{center}\n\nNotes: \\newline\n [1] Standard Errors are heteroscedasticity robust (HC3) \\newline\n [2] The condition number is large, 3.06e+03. This might indicate that there are \\newline\n strong multicollinearity or other numerical problems."
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkYb8j6anXg_"
      },
      "source": [
        "After controlling for a rich set of characteristics, the point estimate of gun ownership attenuates to 0.179.\n",
        "\n",
        "***NB***: In the background, `statsmodels` is dropping variables based on collinearity diagnostics. These depend on system linear algebra routines and can lead to large differences in high-dimensional or other ill-conditioned settings when using otherwise identical code across languages and/or machines.\n",
        "\n",
        "Now we turn to our double machine learning framework, employing linear and flexible estimation methods with cross-fitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "702RF417z6-1"
      },
      "source": [
        "## DML Estimates\n",
        "\n",
        "We perform inference on $\\beta$ in the following the partially linear model:\n",
        " $$\n",
        "Y_{j, t}=\\beta D_{j,(t-1)}+g(Z_{j,t})+\\epsilon_{j, t}.\n",
        "$$\n",
        "In the first stage, using cross-fitting, we employ modern regression methods to build estimators $\\hat \\ell(Z_{j,t})$ and $\\hat m(Z_{j,t})$, where\n",
        "- $\\ell(Z_{j,t}):=E(Y_{j,t}|Z_{j,t})$\n",
        "- $m(Z_{j,t}):=E(D_{j,t}|Z_{j,t})$\n",
        "\n",
        "Using these, we obtain the estimates of the residualized quantities\n",
        "- $\\tilde Y_{j,t} = Y_{j,t}- E(Y_{j,t}|Z_{j,t})$\n",
        "- $\\tilde D_{j,t}= D_{j,t}- E(D_{j,t}|Z_{j,t})$\n",
        "\n",
        "Using these residualized quantities, we note our model can be written as\n",
        "$$\n",
        "\\tilde Y_{j,t} = \\beta \\tilde D_{j,t} + \\epsilon_{j,t}, \\quad E (\\epsilon_{j,t} |\\tilde D_{j,t}) =0.\n",
        "$$\n",
        "In the final stage, using ordinary least squares of $\\tilde Y_{j,t}$ on $\\tilde D_{j,t}$, we obtain the\n",
        "estimate of $\\beta$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1rLIZVx1LNv"
      },
      "source": [
        "In the following, we consider 10 different methods for the first-stage models for $\\ell(\\cdot)$ and $m(\\cdot)$ covering linear, penalized linear, and flexible methods. We also report the first-stage RMSE scores for estimating $Y$ and $D$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sakc09Jv0ggw"
      },
      "outputs": [],
      "source": [
        "def dml(X, D, y, modely, modeld, *, nfolds, classifier=False):\n",
        "    '''\n",
        "    DML for the Partially Linear Model setting with cross-fitting\n",
        "\n",
        "    Input\n",
        "    -----\n",
        "    X: the controls\n",
        "    D: the treatment\n",
        "    y: the outcome\n",
        "    modely: the ML model for predicting the outcome y\n",
        "    modeld: the ML model for predicting the treatment D\n",
        "    nfolds: the number of folds in cross-fitting\n",
        "    classifier: bool, whether the modeld is a classifier or a regressor\n",
        "\n",
        "    time: array of time indices, eg [0,1,...,T-1,0,1,...,T-1,...,0,1,...,T-1]\n",
        "    clu: array of cluster indices, eg [1073, 1073, 1073, ..., 5055, 5055, 5055, 5055]\n",
        "    cluster: bool, whether to use clustered standard errors\n",
        "\n",
        "    Output\n",
        "    ------\n",
        "    point: the point estimate of the treatment effect of D on y\n",
        "    stderr: the standard error of the treatment effect\n",
        "    yhat: the cross-fitted predictions for the outcome y\n",
        "    Dhat: the cross-fitted predictions for the treatment D\n",
        "    resy: the outcome residuals\n",
        "    resD: the treatment residuals\n",
        "    epsilon: the final residual-on-residual OLS regression residual\n",
        "    '''\n",
        "    cv = KFold(n_splits=nfolds, shuffle=True, random_state=123)  # shuffled k-folds\n",
        "    yhat = cross_val_predict(modely, X, y, cv=cv, n_jobs=-1)  # out-of-fold predictions for y\n",
        "    # out-of-fold predictions for D\n",
        "    # use predict or predict_proba dependent on classifier or regressor for D\n",
        "    if classifier:\n",
        "        Dhat = cross_val_predict(modeld, X, D, cv=cv, method='predict_proba', n_jobs=-1)[:, 1]\n",
        "    else:\n",
        "        Dhat = cross_val_predict(modeld, X, D, cv=cv, n_jobs=-1)\n",
        "    # calculate outcome and treatment residuals\n",
        "    resy = y - yhat\n",
        "    resD = D - Dhat\n",
        "\n",
        "    dml_data = pd.concat([pd.Series(resy, name='resy'), pd.Series(resD, name='resD')], axis=1)\n",
        "    ols_mod = smf.ols(formula='resy ~ 1 + resD', data=dml_data).fit()\n",
        "\n",
        "    point = ols_mod.params[1]\n",
        "    stderr = ols_mod.bse[1]\n",
        "    epsilon = ols_mod.resid\n",
        "\n",
        "    return point, stderr, yhat, Dhat, resy, resD, epsilon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4lz1FbliN3q"
      },
      "outputs": [],
      "source": [
        "def summary(point, stderr, yhat, Dhat, resy, resD, epsilon, X, D, y, *, name):\n",
        "    '''\n",
        "    Convenience summary function that takes the results of the DML function\n",
        "    and summarizes several estimation quantities and performance metrics.\n",
        "    '''\n",
        "    return pd.DataFrame({'estimate': point,  # point estimate\n",
        "                         'stderr': stderr,  # standard error\n",
        "                         'lower': point - 1.96 * stderr,  # lower end of 95% confidence interval\n",
        "                         'upper': point + 1.96 * stderr,  # upper end of 95% confidence interval\n",
        "                         'rmse y': np.sqrt(np.mean(resy**2)),  # RMSE of model that predicts outcome y\n",
        "                         'rmse D': np.sqrt(np.mean(resD**2))  # RMSE of model that predicts treatment D\n",
        "                         }, index=[name])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MmOSY9HSJJt0"
      },
      "outputs": [],
      "source": [
        "# OLS No Controls\n",
        "Y = usedata['logghomr']\n",
        "D = usedata['logfssl']\n",
        "Z = pd.DataFrame({\"Const\": np.ones(len(Y))})  # regression on constant\n",
        "\n",
        "modely = make_pipeline(StandardScaler(), LinearRegression())\n",
        "modeld = make_pipeline(StandardScaler(), LinearRegression())\n",
        "\n",
        "# Run DML model with nfolds folds of cross-fitting\n",
        "result_OLS = dml(Z, D, Y, modely, modeld, nfolds=5, classifier=False)\n",
        "table = summary(*result_OLS, Z, D, y, name='OLS No Controls')\n",
        "table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZPsTCxVVUrl"
      },
      "outputs": [],
      "source": [
        "# Basic Controls\n",
        "basic_controls = [d] + X1 + X2 + census\n",
        "Z = usedata[basic_controls].drop(columns=['logfssl'])\n",
        "\n",
        "modely = make_pipeline(StandardScaler(), LinearRegression())\n",
        "modeld = make_pipeline(StandardScaler(), LinearRegression())\n",
        "\n",
        "# Run DML model with nfolds folds of cross-fitting\n",
        "result_basic = dml(Z, D, Y, modely, modeld, nfolds=5, classifier=False)\n",
        "table = pd.concat([table, summary(*result_basic, Z, D, y, name='OLS Basic Controls')])\n",
        "table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNfPSzkzVVDB"
      },
      "outputs": [],
      "source": [
        "# All Controls\n",
        "# Regression on time and cross-sectional averages\n",
        "varlistX = X1 + X2 + census\n",
        "varlistMeans = [d] + X1 + X2 + census\n",
        "\n",
        "# Adding county and time means\n",
        "for var in varlistX:\n",
        "    varlistMeans.append(var + 'J')\n",
        "    varlistMeans.append(var + 'T')\n",
        "\n",
        "Z = sm.add_constant(usedata[varlistMeans].drop(columns=['logfssl']))\n",
        "\n",
        "modely = make_pipeline(StandardScaler(), LinearRegression())\n",
        "modeld = make_pipeline(StandardScaler(), LinearRegression())\n",
        "\n",
        "# Run DML model with nfolds folds of cross-fitting\n",
        "result_all = dml(Z, D, Y, modely, modeld, nfolds=5, classifier=False)\n",
        "table = pd.concat([table, summary(*result_all, Z, D, y, name='OLS All Controls')])\n",
        "table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmnXjQ5uZ5a1"
      },
      "outputs": [],
      "source": [
        "# Now lets do Cross-validated Lasso, Ridge, ENet\n",
        "cv = KFold(n_splits=10, shuffle=True, random_state=123)  # shuffled k-folds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yi-3-yMCZtEK"
      },
      "outputs": [],
      "source": [
        "# Define LassoCV models with n_splits folds of cross-validation\n",
        "modely = make_pipeline(StandardScaler(), LassoCV(cv=cv))\n",
        "modeld = make_pipeline(StandardScaler(), LassoCV(cv=cv))\n",
        "\n",
        "# Run DML model with nfolds folds of cross-fitting\n",
        "result_LassoCV = dml(Z, D, Y, modely, modeld, nfolds=5, classifier=False)\n",
        "table = pd.concat([table, summary(*result_LassoCV, Z, D, y, name='LassoCV')])\n",
        "table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzopGWpJYdcf"
      },
      "outputs": [],
      "source": [
        "# Define RidgeCV models with n_splits folds of cross-validation\n",
        "modely = make_pipeline(StandardScaler(), RidgeCV(cv=cv))\n",
        "modeld = make_pipeline(StandardScaler(), RidgeCV(cv=cv))\n",
        "\n",
        "# Run DML model with nfolds folds of cross-fitting\n",
        "result_RidgeCV = dml(Z, D, Y, modely, modeld, nfolds=5, classifier=False)\n",
        "table = pd.concat([table, summary(*result_RidgeCV, Z, D, y, name='RidgeCV')])\n",
        "table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOC2nho2oXjY"
      },
      "outputs": [],
      "source": [
        "# Define ElasticNetCV models with n_splits folds of cross-validation\n",
        "modely = make_pipeline(StandardScaler(), ElasticNetCV(l1_ratio=0.5, cv=cv))\n",
        "modeld = make_pipeline(StandardScaler(), ElasticNetCV(l1_ratio=0.5, cv=cv))\n",
        "\n",
        "# Run DML model with nfolds folds of cross-fitting\n",
        "result_ENetCV = dml(Z, D, Y, modely, modeld, nfolds=5, classifier=False)\n",
        "table = pd.concat([table, summary(*result_ENetCV, Z, D, y, name='ENetCV')])\n",
        "table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBRrdvgwfbHp"
      },
      "outputs": [],
      "source": [
        "# DML with Random Forests. RFs don't require scaling but we do it for consistency\n",
        "modely = make_pipeline(StandardScaler(), RandomForestRegressor(n_estimators=100, min_samples_leaf=5, random_state=123))\n",
        "modeld = make_pipeline(StandardScaler(), RandomForestRegressor(n_estimators=100, min_samples_leaf=5, random_state=123))\n",
        "\n",
        "# Run DML model with nfolds folds of cross-fitting (computationally intensive)\n",
        "result_RF = dml(Z, D, Y, modely, modeld, nfolds=5, classifier=False)\n",
        "table = pd.concat([table, summary(*result_RF, Z, D, y, name='RF')])\n",
        "table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnusdWH0bF6u"
      },
      "outputs": [],
      "source": [
        "# DML with Boosted Trees\n",
        "modely = make_pipeline(StandardScaler(), GradientBoostingRegressor(max_depth=4, n_iter_no_change=5))\n",
        "modeld = make_pipeline(StandardScaler(), GradientBoostingRegressor(max_depth=4, n_iter_no_change=5))\n",
        "\n",
        "# Run DML model with nfolds folds of cross-fitting (computationally intensive)\n",
        "result_BT = dml(Z, D, Y, modely, modeld, nfolds=5, classifier=False)\n",
        "table = pd.concat([table, summary(*result_BT, Z, D, y, name='Boosted Trees')])\n",
        "table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ke7GwmzBqfoO"
      },
      "outputs": [],
      "source": [
        "# DML with NNs\n",
        "modely = make_pipeline(StandardScaler(),\n",
        "                       MLPRegressor(hidden_layer_sizes=(50, 50, 50, 50),\n",
        "                                    activation='relu',\n",
        "                                    solver='adam',\n",
        "                                    alpha=0.0001,\n",
        "                                    batch_size=200,\n",
        "                                    learning_rate='constant',\n",
        "                                    learning_rate_init=0.001,\n",
        "                                    max_iter=200,\n",
        "                                    shuffle=True,\n",
        "                                    random_state=None,\n",
        "                                    tol=1e-4,\n",
        "                                    verbose=False,\n",
        "                                    warm_start=False,\n",
        "                                    momentum=0.9,\n",
        "                                    nesterovs_momentum=True,\n",
        "                                    early_stopping=True,\n",
        "                                    validation_fraction=0.2,\n",
        "                                    beta_1=0.9,\n",
        "                                    beta_2=0.999,\n",
        "                                    epsilon=1e-08,\n",
        "                                    n_iter_no_change=10)\n",
        "                       )\n",
        "modeld = make_pipeline(StandardScaler(),\n",
        "                       MLPRegressor(hidden_layer_sizes=(50, 50, 50, 50),\n",
        "                                    activation='relu',\n",
        "                                    solver='adam',\n",
        "                                    alpha=0.0001,\n",
        "                                    batch_size=200,\n",
        "                                    learning_rate='constant',\n",
        "                                    learning_rate_init=0.001,\n",
        "                                    max_iter=200,\n",
        "                                    shuffle=True,\n",
        "                                    random_state=None,\n",
        "                                    tol=1e-4,\n",
        "                                    verbose=False,\n",
        "                                    warm_start=False,\n",
        "                                    momentum=0.9,\n",
        "                                    nesterovs_momentum=True,\n",
        "                                    early_stopping=True,\n",
        "                                    validation_fraction=0.2,\n",
        "                                    beta_1=0.9,\n",
        "                                    beta_2=0.999,\n",
        "                                    epsilon=1e-08,\n",
        "                                    n_iter_no_change=10)\n",
        "                       )\n",
        "\n",
        "# Run DML model with nfolds folds of cross-fitting\n",
        "result_NN = dml(Z, D, Y, modely, modeld, nfolds=5, classifier=False)\n",
        "table = pd.concat([table, summary(*result_NN, Z, D, y, name='NN (Early Stopping)')])\n",
        "table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "syua99Emazgl"
      },
      "outputs": [],
      "source": [
        "rmses = table.iloc[:, -2:]\n",
        "rmses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O2g0u1iR0qtT"
      },
      "outputs": [],
      "source": [
        "print(\"Lowest RMSE y: \", rmses.iloc[:, 0].idxmin())\n",
        "print(\"Lowest RMSE D: \", rmses.iloc[:, 1].idxmin())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RISoyJQ51G2g"
      },
      "outputs": [],
      "source": [
        "# DML with best model, which is RF\n",
        "modely = make_pipeline(StandardScaler(), RandomForestRegressor(n_estimators=100, min_samples_leaf=5, random_state=123))\n",
        "modeld = make_pipeline(StandardScaler(), RandomForestRegressor(n_estimators=100, min_samples_leaf=5, random_state=123))\n",
        "\n",
        "# Run DML model with nfolds folds of cross-fitting (computationally intensive)\n",
        "result_best = dml(Z, D, Y, modely, modeld, nfolds=5, classifier=False)\n",
        "table = pd.concat([table, summary(*result_best, Z, D, y, name='Best')])\n",
        "table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_0ANZmw2GX2"
      },
      "outputs": [],
      "source": [
        "# Least Squares Model Average\n",
        "yhat_all = pd.concat([\n",
        "    pd.Series(result_OLS[2]),\n",
        "    pd.Series(result_basic[2]),\n",
        "    pd.Series(result_all[2]),\n",
        "    pd.Series(result_LassoCV[2]),\n",
        "    pd.Series(result_RidgeCV[2]),\n",
        "    pd.Series(result_ENetCV[2]),\n",
        "    pd.Series(result_RF[2]),\n",
        "    pd.Series(result_BT[2]),\n",
        "    pd.Series(result_NN[2])\n",
        "], axis=1)\n",
        "\n",
        "Dhat_all = pd.concat([\n",
        "    pd.Series(result_OLS[3]),\n",
        "    pd.Series(result_basic[3]),\n",
        "    pd.Series(result_all[3]),\n",
        "    pd.Series(result_LassoCV[3]),\n",
        "    pd.Series(result_RidgeCV[3]),\n",
        "    pd.Series(result_ENetCV[3]),\n",
        "    pd.Series(result_RF[3]),\n",
        "    pd.Series(result_BT[3]),\n",
        "    pd.Series(result_NN[3])\n",
        "], axis=1)\n",
        "\n",
        "ma_y = sm.OLS(usedata['logghomr'], yhat_all).fit()\n",
        "ma_d = sm.OLS(usedata['logfssl'], Dhat_all).fit()\n",
        "\n",
        "weights_y = ma_y.params\n",
        "weights_d = ma_d.params\n",
        "\n",
        "lm_k = sm.OLS(ma_y.resid, ma_d.resid).fit(cov_type='HC3')\n",
        "lsma = pd.Series({\"estimate\": lm_k.params[0], \"stderr\": lm_k.bse[0]},\n",
        "                 name=\"Least Squares Model Average\").to_frame().T\n",
        "\n",
        "final_table = table.iloc[:, :2]\n",
        "final_table = pd.concat([final_table, lsma], axis=0)\n",
        "final_table"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 663.673787,
      "end_time": "2021-07-23T16:28:56.086168",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2021-07-23T16:17:52.412381",
      "version": "2.2.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}